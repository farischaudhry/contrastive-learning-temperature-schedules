{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7d8ed9",
   "metadata": {},
   "source": [
    "# Temperature Annealing for Contrastive Learning\n",
    "\n",
    "## Simulation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa04c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vmap, lax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"anisotropic_annealing_experiments\"\n",
    "SAVE_DIR = f\"./results/{EXP_NAME}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Set seeds\n",
    "GLOBAL_SEED = 42\n",
    "key = jax.random.PRNGKey(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "\n",
    "# Global Hyperparameters \n",
    "GLOBAL_CONFIG = {\n",
    "    \"N_POINTS\": 4,\n",
    "    \"DIM\": 3,\n",
    "    \"POSITIVE_PAIRS\": [(0, 1), (2, 3)],  # toy contrastive pairs\n",
    "    \"dt\": 0.01,  # discretization step\n",
    "    \"max_steps_exp1\": 50000,\n",
    "    \"max_steps_exp2\": 200000,\n",
    "    \"success_threshold\": -1.5, \n",
    "}\n",
    "with open(os.path.join(SAVE_DIR, \"config.json\"), \"w\") as f:\n",
    "    json.dump(GLOBAL_CONFIG, f, indent=4)\n",
    "\n",
    "N_POINTS = GLOBAL_CONFIG[\"N_POINTS\"]\n",
    "DIM = GLOBAL_CONFIG[\"DIM\"]\n",
    "POSITIVE_PAIRS = jnp.array(GLOBAL_CONFIG[\"POSITIVE_PAIRS\"])\n",
    "DT = GLOBAL_CONFIG[\"dt\"]\n",
    "SUCCESS_THRESHOLD = GLOBAL_CONFIG[\"success_threshold\"]\n",
    "\n",
    "\n",
    "# Potential and projection functions\n",
    "\n",
    "@jit\n",
    "def U0(Z):\n",
    "    \"\"\"Limiting potential U0(Z).\"\"\"\n",
    "    Z_norm = Z / jnp.linalg.norm(Z, axis=1, keepdims=True)\n",
    "    sim_matrix = jnp.dot(Z_norm, Z_norm.T)\n",
    "\n",
    "    def potential_for_pair(pair):\n",
    "        i, j = pair[0], pair[1]\n",
    "        pos_sim = sim_matrix[i, j]\n",
    "\n",
    "        # mask to ignore positives/self\n",
    "        mask = jnp.zeros_like(sim_matrix[i, :]).at[jnp.array([i, j])].set(-jnp.inf)\n",
    "        hardest_neg_i = jnp.max(sim_matrix[i, :] + mask)\n",
    "        hardest_neg_j = jnp.max(sim_matrix[j, :] + mask)\n",
    "\n",
    "        energy = (-pos_sim + hardest_neg_i) + (-pos_sim + hardest_neg_j)\n",
    "        return energy\n",
    "\n",
    "    total_energy = jnp.sum(jax.lax.map(potential_for_pair, POSITIVE_PAIRS))\n",
    "    return total_energy / (2 * len(POSITIVE_PAIRS))  # can use 1/2 since sim function is symmetric\n",
    "\n",
    "grad_U0 = jit(grad(U0))\n",
    "\n",
    "@jit\n",
    "def renormalize(Z):\n",
    "    \"\"\"Project back to unit sphere (row-wise).\"\"\"\n",
    "    return Z / jnp.linalg.norm(Z, axis=1, keepdims=True)\n",
    "\n",
    "@jit\n",
    "def get_projection_matrix(point):\n",
    "    \"\"\"Projection to tangent space at a point on the sphere.\"\"\"\n",
    "    return jnp.eye(DIM) - jnp.outer(point, point)\n",
    "\n",
    "batch_get_projection_matrix = vmap(get_projection_matrix)\n",
    "\n",
    "\n",
    "# SDE Step Functions\n",
    "\n",
    "def isotropic_sde_step(Z, t_idx, c, dt, key):\n",
    "    \"\"\"One isotropic annealing SDE step.\"\"\"\n",
    "    t = t_idx * dt\n",
    "    beta_t = c * jnp.log(t + 1.0)\n",
    "    beta_t = jnp.maximum(beta_t, 1e-6)\n",
    "\n",
    "    step_key = jax.random.fold_in(key, t_idx)\n",
    "    dW_ambient = jax.random.normal(step_key, shape=Z.shape)\n",
    "    projection_matrices = batch_get_projection_matrix(Z)\n",
    "    dW_tangent = jnp.einsum(\"bij,bj->bi\", projection_matrices, dW_ambient)\n",
    "\n",
    "    drift = -grad_U0(Z) * dt\n",
    "    noise = dW_tangent * jnp.sqrt(2 * dt / beta_t)\n",
    "\n",
    "    return renormalize(Z + drift + noise), None\n",
    "\n",
    "def anisotropic_sde_step(Z, t_idx, c, dt, key, A):\n",
    "    \"\"\"One anisotropic annealing SDE step with diffusion A.\"\"\"\n",
    "    t = t_idx * dt\n",
    "    beta_t = c * jnp.log(t + 1.0)\n",
    "    beta_t = jnp.maximum(beta_t, 1e-6)\n",
    "    B = jnp.sqrt(A)\n",
    "\n",
    "    step_key = jax.random.fold_in(key, t_idx)\n",
    "    dW_ambient = jax.random.normal(step_key, shape=Z.shape)\n",
    "\n",
    "    # Use B (the matrix sqrt) instead of A\n",
    "    dW_aniso = jnp.einsum(\"ij,bj->bi\", B, dW_ambient)\n",
    "\n",
    "    projection_matrices = batch_get_projection_matrix(Z)\n",
    "    dW_tangent = jnp.einsum(\"bij,bj->bi\", projection_matrices, dW_aniso)\n",
    "\n",
    "    drift = -grad_U0(Z) * dt\n",
    "    noise = dW_tangent * jnp.sqrt(2 * dt / beta_t)\n",
    "\n",
    "    return renormalize(Z + drift + noise), None\n",
    "\n",
    "def fixed_temp_sde_step(Z, t_idx, beta_fixed, dt, key, B):\n",
    "    step_key = jax.random.fold_in(key, t_idx)\n",
    "    dW_ambient = jax.random.normal(step_key, shape=Z.shape)\n",
    "    dW_aniso = jnp.einsum(\"ij,bj->bi\", B, dW_ambient)\n",
    "    projection_matrices = batch_get_projection_matrix(Z)\n",
    "    dW_tangent = jnp.einsum(\"bij,bj->bi\", projection_matrices, dW_aniso)\n",
    "    drift = -grad_U0(Z) * dt\n",
    "    noise = dW_tangent * jnp.sqrt(2 * dt / beta_fixed)\n",
    "    return renormalize(Z + drift + noise), None\n",
    "\n",
    "print(f\"Base framework initialized. Saving results to: {SAVE_DIR}\")\n",
    "\n",
    "\n",
    "# Generic Simulation Harness\n",
    "\n",
    "def simulate_one_run_iso(key, c, n_steps, dt):\n",
    "    \"\"\"Simulate one isotropic run.\"\"\"\n",
    "    Z = renormalize(jax.random.normal(key, shape=(N_POINTS, DIM)))\n",
    "\n",
    "    def step_fn(Z, t_idx):\n",
    "        return isotropic_sde_step(Z, t_idx, c, dt, key)\n",
    "\n",
    "    final_Z, _ = jax.lax.scan(step_fn, Z, jnp.arange(n_steps))\n",
    "    return final_Z\n",
    "\n",
    "def simulate_one_run_aniso(key, c, n_steps, dt, A):\n",
    "    \"\"\"Simulate one anisotropic run with diffusion matrix A.\"\"\"\n",
    "    Z = renormalize(jax.random.normal(key, shape=(N_POINTS, DIM)))\n",
    "\n",
    "    def step_fn(Z, t_idx):\n",
    "        return anisotropic_sde_step(Z, t_idx, c, dt, key, A)\n",
    "\n",
    "    final_Z, _ = jax.lax.scan(step_fn, Z, jnp.arange(n_steps))\n",
    "    return final_Z\n",
    "\n",
    "def simulate_one_run_fixed(key, beta_fixed, n_steps, dt, B):\n",
    "    Z = renormalize(jax.random.normal(key, shape=(N_POINTS, DIM)))\n",
    "    def step_fn(Z, t_idx):\n",
    "        return fixed_temp_sde_step(Z, t_idx, beta_fixed, dt, key, B)\n",
    "    final_Z, _ = jax.lax.scan(step_fn, Z, jnp.arange(n_steps))\n",
    "    return final_Z\n",
    "\n",
    "batch_simulate_iso = jit(\n",
    "    vmap(simulate_one_run_iso, in_axes=(0, None, None, None)),\n",
    "    static_argnums=(2,)\n",
    ")\n",
    "\n",
    "batch_simulate_aniso = jit(\n",
    "    vmap(simulate_one_run_aniso, in_axes=(0, None, None, None, None)),\n",
    "    static_argnums=(2,)\n",
    ")\n",
    "\n",
    "batch_simulate_fixed = jit(\n",
    "    vmap(simulate_one_run_fixed, in_axes=(0, None, None, None, None)),\n",
    "    static_argnums=(2,)\n",
    ")\n",
    "\n",
    "\n",
    "# Wilson Score Interval Function\n",
    "\n",
    "def wilson_score_interval(p, n, z=1.96):\n",
    "    \"\"\"Calculates the Wilson score interval for a binomial proportion.\"\"\"\n",
    "    if n == 0 or p is None: return (0, 1)\n",
    "    p = float(p); n = int(n)\n",
    "    numerator = p + z**2 / (2 * n); denominator = 1 + z**2 / n\n",
    "    term = z * np.sqrt(p * (1 - p) / n + z**2 / (4 * n**2))\n",
    "    lower = (numerator - term) / denominator; upper = (numerator + term) / denominator\n",
    "    return (max(0, lower), min(1, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942f288",
   "metadata": {},
   "source": [
    "## Experiment 1: Annealing Rate Sweep\n",
    "\n",
    "### Annealed Success Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "112ebb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_c(beta_target, T_max):\n",
    "    return beta_target / math.log(T_max + 1.0)\n",
    "\n",
    "def build_default_c_grid(beta_target, dt, max_steps, n_coarse=30, n_dense=30):\n",
    "    \"\"\"\n",
    "    Build a practical default c grid that avoids trivially truncated c values.\n",
    "    \"\"\"\n",
    "    T_max = max_steps * dt\n",
    "    c_min_feasible = compute_min_c(beta_target, T_max)\n",
    "    # guard\n",
    "    c_min = max(0.5, c_min_feasible * 0.8)  # slightly below feasible to allow a few truncated points\n",
    "    c_hi = 200.0\n",
    "    coarse = np.logspace(np.log10(c_min), np.log10(c_hi), n_coarse)\n",
    "    dense = np.linspace(max(c_min, 1.0), min(25.0, c_hi), n_dense)\n",
    "    c_vals = np.unique(np.concatenate([coarse, dense]))\n",
    "    c_vals = np.sort(c_vals)\n",
    "    return c_vals, c_min_feasible\n",
    "\n",
    "def run_experiment_1(\n",
    "    beta_target=10.0,\n",
    "    c_values=None,\n",
    "    n_runs_base=1024,\n",
    "    min_runs=64,\n",
    "    max_runs=2048,\n",
    "    dt=GLOBAL_CONFIG[\"dt\"],\n",
    "    max_steps=GLOBAL_CONFIG[\"max_steps_exp1\"],\n",
    "    success_threshold=GLOBAL_CONFIG[\"success_threshold\"],\n",
    "    A_aniso=jnp.diag(jnp.array([10.0, 10.0, 0.01])),\n",
    "    save_dir=SAVE_DIR,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Experiment 1: Sweep annealing rate c and estimate success probability for isotropic and anisotropic SDEs.\n",
    "    \"\"\"\n",
    "    global key\n",
    "\n",
    "    # Make grid if none provided\n",
    "    if c_values is None:\n",
    "        c_values, c_min_feasible = build_default_c_grid(beta_target, dt, max_steps)\n",
    "        if verbose:\n",
    "            print(f\"[Info] Auto c-grid built. c_min_feasible ≈ {c_min_feasible:.4f}, using {len(c_values)} c values.\")\n",
    "    else:\n",
    "        c_values = np.asarray(c_values)\n",
    "        T_max = max_steps * dt\n",
    "        c_min_feasible = compute_min_c(beta_target, T_max)\n",
    "        if verbose:\n",
    "            print(f\"[Info] Using provided c_values (len={len(c_values)}). c_min_feasible ≈ {c_min_feasible:.4f}\")\n",
    "\n",
    "    results = []\n",
    "    meta = {\n",
    "        \"GLOBAL_SEED\": int(GLOBAL_SEED),\n",
    "        \"N_POINTS\": int(N_POINTS),\n",
    "        \"DIM\": int(DIM),\n",
    "        \"dt\": float(dt),\n",
    "        \"max_steps\": int(max_steps),\n",
    "        \"beta_target\": float(beta_target),\n",
    "        \"success_threshold\": float(success_threshold),\n",
    "        \"A_aniso_diag\": list(map(float, jnp.diag(A_aniso))),\n",
    "        \"n_runs_base\": int(n_runs_base),\n",
    "        \"min_runs\": int(min_runs),\n",
    "        \"max_runs\": int(max_runs),\n",
    "        \"timestamp\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    out_json = os.path.join(save_dir, \"experiment1_results.json\")\n",
    "    out_plot = os.path.join(save_dir, \"experiment1_plot.png\")\n",
    "\n",
    "    pbar = tqdm(c_values, desc=\"Experiment 1 c-sweep\")\n",
    "    for c in pbar:\n",
    "        # compute required continuous time and steps to reach beta_target\n",
    "        # Check for potential overflow BEFORE calling math.exp()\n",
    "        exponent = beta_target / float(c)\n",
    "        if exponent > 709:  # math.exp(709.78) is roughly the max float64\n",
    "            required_steps = max_steps\n",
    "            truncated = True\n",
    "            T_final = float('inf')\n",
    "        else:\n",
    "            T_final = math.exp(exponent) - 1.0\n",
    "            required_steps = int(min(math.ceil(T_final / dt), max_steps))\n",
    "            truncated = (T_final / dt) > max_steps\n",
    "\n",
    "        # heuristic adapt number of runs by cost\n",
    "        # scale = min(1.0, max_steps / required_steps)\n",
    "        if required_steps <= 0:\n",
    "            scale = 1.0\n",
    "        else:\n",
    "            scale = min(1.0, float(max_steps) / float(required_steps))\n",
    "        n_runs = int(max(min_runs, min(max_runs, round(n_runs_base * scale))))\n",
    "\n",
    "        start_key_int = int(key[0]) if hasattr(key, \"shape\") else int(key)  # key is uint32 array\n",
    "        keys = jax.random.split(key, n_runs + 1)\n",
    "        run_keys = keys[:-1]\n",
    "        key = keys[-1]  # update global key for next loop\n",
    "\n",
    "        # Run isotropic\n",
    "        try:\n",
    "            final_Zs_iso = batch_simulate_iso(run_keys, c, required_steps, dt)\n",
    "            energies_iso = np.asarray(vmap(U0)(final_Zs_iso))\n",
    "            prob_iso = float(np.mean(energies_iso < success_threshold))\n",
    "            frac_never_iso = float(np.mean(energies_iso >= success_threshold))\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] isotropic run failed for c={c}: {e}\")\n",
    "            prob_iso = None\n",
    "            frac_never_iso = None\n",
    "\n",
    "        # Run anisotropic\n",
    "        try:\n",
    "            final_Zs_aniso = batch_simulate_aniso(run_keys, c, required_steps, dt, A_aniso)\n",
    "            energies_aniso = np.asarray(vmap(U0)(final_Zs_aniso))\n",
    "            prob_aniso = float(np.mean(energies_aniso < success_threshold))\n",
    "            frac_never_aniso = float(np.mean(energies_aniso >= success_threshold))\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] anisotropic run failed for c={c}: {e}\")\n",
    "            prob_aniso = None\n",
    "            frac_never_aniso = None\n",
    "\n",
    "        beta_reached = float(c * math.log(required_steps * dt + 1.0))\n",
    "\n",
    "        entry = {\n",
    "            \"c\": float(c),\n",
    "            \"required_steps\": int(required_steps),\n",
    "            \"truncated\": bool(truncated),\n",
    "            \"n_runs\": int(n_runs),\n",
    "            \"start_key_int\": int(start_key_int),\n",
    "            \"beta_target\": float(beta_target),\n",
    "            \"beta_reached\": beta_reached,\n",
    "            \"prob_iso\": prob_iso,\n",
    "            \"prob_aniso\": prob_aniso,\n",
    "            \"frac_never_iso\": frac_never_iso,\n",
    "            \"frac_never_aniso\": frac_never_aniso,\n",
    "            \"success_threshold\": float(success_threshold)\n",
    "        }\n",
    "        results.append(entry)\n",
    "\n",
    "        # incremental save (meta + results)\n",
    "        with open(out_json, \"w\") as f:\n",
    "            json.dump({\"meta\": meta, \"results\": results}, f, indent=2)\n",
    "\n",
    "        pbar.set_description(f\"c={c:.3g}, steps={required_steps}, runs={n_runs}\")\n",
    "        time.sleep(0.01)\n",
    "\n",
    "    # Make a quick debugging plot (only plot non-None results)\n",
    "    cs = np.array([r[\"c\"] for r in results if r[\"prob_iso\"] is not None])\n",
    "    probs_iso = np.array([r[\"prob_iso\"] for r in results if r[\"prob_iso\"] is not None])\n",
    "    probs_aniso = np.array([r[\"prob_aniso\"] for r in results if r[\"prob_aniso\"] is not None])\n",
    "\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(cs, probs_iso, \"o-\", label=\"Isotropic\")\n",
    "    plt.plot(cs, probs_aniso, \"s-\", label=f\"Anisotropic (diag={meta['A_aniso_diag']})\")\n",
    "    plt.axhline(y=0.5, color=\"grey\", linestyle=\"--\", alpha=0.7, label=\"50% Threshold\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xlabel(\"Annealing Rate c (log scale)\")\n",
    "    plt.ylabel(\"Success Probability\")\n",
    "    plt.title(f\"Experiment 1: Convergence Probability vs Annealing Rate (beta_target={beta_target})\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_plot, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[Done] Results saved to {out_json} and {out_plot}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176abc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_small = jnp.diag(jnp.array([1.,1.,0.1]))\n",
    "A_large = jnp.diag(jnp.array([20.0, 20.0, 10.0]))\n",
    "\n",
    "run_experiment_1(\n",
    "    beta_target=10.0,\n",
    "    n_runs_base=1024,\n",
    "    A_aniso=A_small,\n",
    "    max_runs=2048,\n",
    "    min_runs=128,\n",
    "    save_dir='./results/aniso_small',\n",
    ")\n",
    "run_experiment_1(\n",
    "    beta_target=10.0,\n",
    "    n_runs_base=1024,\n",
    "    A_aniso=A_large,\n",
    "    max_runs=2048,\n",
    "    min_runs=128,\n",
    "    save_dir='./results/aniso_large',\n",
    ")\n",
    "\n",
    "# Slower ansio run\n",
    "# c_values_slow = np.logspace(-1, 2.5, 40) # 40 points from c=10^-1 to c=10^2.5\n",
    "# run_experiment_1(\n",
    "#     beta_target=200.0,  # The new, higher target to allow annealing\n",
    "#     c_values=c_values_slow,\n",
    "#     n_runs_base=2048,  # Use a high number of runs for tigher bounds\n",
    "#     max_steps=200000,  # Increase max_steps to allow the schedule to complete\n",
    "#     A_aniso=A_large,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16d85a",
   "metadata": {},
   "source": [
    "### Experiment 1 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a20c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def create_figure_1a(\n",
    "    saved_small_aniso_path,\n",
    "    saved_large_aniso_path,\n",
    "    save_dir,\n",
    "    precomputed_fixed_beta_path=None,\n",
    "    beta_fixed=10.0,\n",
    "    n_runs_fixed=2048,\n",
    "    simulation_steps_fixed=50000,\n",
    "):\n",
    "    global key\n",
    "    print(\"Loading and processing annealed results\")\n",
    "    try:\n",
    "        with open(saved_small_aniso_path, 'r') as f: data_small = json.load(f)\n",
    "        df_small = pd.DataFrame(data_small['results']); meta_small = data_small['meta']\n",
    "        with open(saved_large_aniso_path, 'r') as f: data_large = json.load(f)\n",
    "        df_large = pd.DataFrame(data_large['results']); meta_large = data_large['meta']\n",
    "    except FileNotFoundError as e: print(f\"ERROR: Could not find result file: {e}. Please check paths.\"); return\n",
    "    df_iso = df_small[['c', 'n_runs', 'prob_iso']].copy()\n",
    "    df_iso['ci_lower'], df_iso['ci_upper'] = zip(*[wilson_score_interval(p, n) for p, n in zip(df_iso['prob_iso'], df_iso['n_runs'])])\n",
    "    df_small['ci_lower'], df_small['ci_upper'] = zip(*[wilson_score_interval(p, n) for p, n in zip(df_small['prob_aniso'], df_small['n_runs'])])\n",
    "    df_large['ci_lower'], df_large['ci_upper'] = zip(*[wilson_score_interval(p, n) for p, n in zip(df_large['prob_aniso'], df_large['n_runs'])])\n",
    "    fixed_beta_results = None\n",
    "    if precomputed_fixed_beta_path and os.path.exists(precomputed_fixed_beta_path):\n",
    "        print(f\"\\nLoading pre-computed fixed-beta results from: {precomputed_fixed_beta_path}\")\n",
    "        with open(precomputed_fixed_beta_path, 'r') as f: fixed_beta_results = json.load(f)\n",
    "    local_cache_file = os.path.join(save_dir, f\"fixed_beta_{beta_fixed}_results.json\")\n",
    "    if fixed_beta_results is None and os.path.exists(local_cache_file):\n",
    "        print(f\"\\n Loading cached fixed-beta results from: {local_cache_file}\")\n",
    "        with open(local_cache_file, 'r') as f: fixed_beta_results = json.load(f)\n",
    "    if fixed_beta_results is None:\n",
    "        print(f\"\\n No cache found. Running fixed beta={beta_fixed} simulations ({n_runs_fixed} runs each)\")\n",
    "        B_iso=jnp.eye(DIM); A_small=jnp.diag(jnp.array(meta_small['A_aniso_diag'])); B_small=jnp.sqrt(A_small); A_large=jnp.diag(jnp.array(meta_large['A_aniso_diag'])); B_large=jnp.sqrt(A_large)\n",
    "        models = {\"Isotropic\": B_iso, \"Aniso-Small\": B_small, \"Aniso-Large\": B_large}; fixed_beta_results = {}\n",
    "        for name, B in models.items():\n",
    "            keys = jax.random.split(key, n_runs_fixed + 1); run_keys, key = keys[:-1], keys[-1]\n",
    "            final_Z = batch_simulate_fixed(run_keys, beta_fixed, simulation_steps_fixed, DT, B); valid_energies = vmap(U0)(final_Z)\n",
    "            success_runs = jnp.sum(valid_energies < SUCCESS_THRESHOLD); prob = float(success_runs) / n_runs_fixed\n",
    "            ci_lower, ci_upper = wilson_score_interval(prob, n_runs_fixed); fixed_beta_results[name] = {\"prob\": prob, \"ci\": [ci_lower, ci_upper]}\n",
    "            print(f\"  Success Prob (Fixed Beta, {name}): {prob:.4f} (95% CI: [{ci_lower:.4f}, {ci_upper:.4f}])\")\n",
    "        with open(local_cache_file, 'w') as f: json.dump(fixed_beta_results, f, indent=4)\n",
    "        print(f\" Caching new results to: {local_cache_file}\")\n",
    "\n",
    "    print(\"\\n Generating final plot\")\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "    colors = {\"iso\": \"#2ecc71\", \"small\": \"#3498db\", \"large\": \"#e74c3c\"}\n",
    "\n",
    "    # Plot Annealed Data\n",
    "    ax.plot(df_iso['c'], df_iso['prob_iso'], 'o-', label=\"Annealed Isotropic\", color=colors['iso'], markersize=5, zorder=10)\n",
    "    ax.fill_between(df_iso['c'], df_iso['ci_lower'], df_iso['ci_upper'], color=colors['iso'], alpha=0.2)\n",
    "    ax.plot(df_small['c'], df_small['prob_aniso'], 's-', label=\"Annealed Aniso-Small\", color=colors['small'], markersize=5, zorder=10)\n",
    "    ax.fill_between(df_small['c'], df_small['ci_lower'], df_small['ci_upper'], color=colors['small'], alpha=0.2)\n",
    "    ax.plot(df_large['c'], df_large['prob_aniso'], '^-', label=\"Annealed Aniso-Large\", color=colors['large'], markersize=5, zorder=10)\n",
    "    ax.fill_between(df_large['c'], df_large['ci_lower'], df_large['ci_upper'], color=colors['large'], alpha=0.2)\n",
    "\n",
    "    # Plot Fixed Beta Baselines\n",
    "    for name, color in [(\"Isotropic\", colors['iso']), (\"Aniso-Small\", colors['small']), (\"Aniso-Large\", colors['large'])]:\n",
    "        res = fixed_beta_results[name]\n",
    "        prob_str = f\"{res['prob']:.3f}\"\n",
    "        label = f'Fixed β={beta_fixed} {name} (P={prob_str})'\n",
    "        ax.axhline(y=res[\"prob\"], color=color, linestyle='--', label=label, linewidth=2.5)\n",
    "        ax.axhspan(res[\"ci\"][0], res[\"ci\"][1], color=color, alpha=0.1)\n",
    "    \n",
    "    title_str = f\"Success Probability vs. Annealing Rate ($\\\\beta_{{target}}={meta_small['beta_target']}$)\"\n",
    "    ax.set_title(title_str, fontsize=20, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel(\"Annealing Rate c (log scale)\", fontsize=18, fontweight='bold')\n",
    "    ax.set_ylabel(\"Success Probability\", fontsize=18, fontweight='bold')\n",
    "    \n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "\n",
    "    ax.grid(True, which=\"both\", linestyle=':', linewidth=1.2, alpha=0.6)\n",
    "    \n",
    "    legend = ax.legend(\n",
    "        loc='upper right', \n",
    "        bbox_to_anchor=(0.98, 0.9),\n",
    "        fontsize=12,\n",
    "        frameon=True,\n",
    "        shadow=False,\n",
    "        title=\"Model\",\n",
    "        title_fontsize=13\n",
    "    )\n",
    "    plt.setp(legend.get_title(), fontweight='bold') \n",
    "\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    out_plot = os.path.join(save_dir, f\"figure_1a_beta{int(beta_fixed)}.png\")\n",
    "    plt.savefig(out_plot, dpi=300)\n",
    "    print(f\"\\n[Success] Final plot saved to {out_plot}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PATH_TO_SMALL_ANISO_RESULTS = 'anisotropic_experiments/experiment1/aniso_small_beta_10/results.json'\n",
    "    PATH_TO_LARGE_ANISO_RESULTS = 'anisotropic_experiments/experiment1/aniso_large_beta_10/results.json' \n",
    "    PRECOMPUTED_CACHE_PATH = os.path.join(\"anisotropic_experiments\", \"experiment1\", \"fixed_beta_10_results.json\")\n",
    "    final_plot_dir = \"./results/final_figures\"\n",
    "    os.makedirs(final_plot_dir, exist_ok=True)\n",
    "\n",
    "    create_figure_1a(\n",
    "        saved_small_aniso_path=PATH_TO_SMALL_ANISO_RESULTS,\n",
    "        saved_large_aniso_path=PATH_TO_LARGE_ANISO_RESULTS,\n",
    "        save_dir=final_plot_dir,\n",
    "        precomputed_fixed_beta_path=PRECOMPUTED_CACHE_PATH,\n",
    "        beta_fixed=10.0,\n",
    "        n_runs_fixed=2048,\n",
    "        simulation_steps_fixed=50000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "def create_figure_1b(\n",
    "    saved_beta200_path,\n",
    "    save_dir,\n",
    "    precomputed_fixed_beta_path=None,\n",
    "    beta_fixed=200.0,\n",
    "    n_runs_fixed=2048,\n",
    "):\n",
    "    global key\n",
    "\n",
    "    print(\"Loading and processing beta_target=200 results\")\n",
    "    try:\n",
    "        with open(saved_beta200_path, 'r') as f: data = json.load(f)\n",
    "        df = pd.DataFrame(data['results'])\n",
    "        meta = data['meta']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"ERROR: Could not find result file: {e}. Please check path.\")\n",
    "        return\n",
    "        \n",
    "    df_iso = df[['c', 'n_runs', 'prob_iso']].copy()\n",
    "    df_aniso = df[['c', 'n_runs', 'prob_aniso']].copy()\n",
    "\n",
    "    df_iso['ci_lower'], df_iso['ci_upper'] = zip(*[wilson_score_interval(p, n) for p, n in zip(df_iso['prob_iso'], df_iso['n_runs'])])\n",
    "    df_aniso['ci_lower'], df_aniso['ci_upper'] = zip(*[wilson_score_interval(p, n) for p, n in zip(df_aniso['prob_aniso'], df_aniso['n_runs'])])\n",
    "\n",
    "    # Simulate or Load Fixed-Beta Baselines\n",
    "    fixed_beta_results = None\n",
    "    if precomputed_fixed_beta_path and os.path.exists(precomputed_fixed_beta_path):\n",
    "        print(f\"\\nLoading pre-computed fixed-beta={beta_fixed} results from: {precomputed_fixed_beta_path}\")\n",
    "        with open(precomputed_fixed_beta_path, 'r') as f: fixed_beta_results = json.load(f)\n",
    "\n",
    "    local_cache_file = os.path.join(save_dir, f\"fixed_beta_{beta_fixed}_results.json\")\n",
    "    if fixed_beta_results is None and os.path.exists(local_cache_file):\n",
    "        print(f\"\\nLoading cached fixed-beta={beta_fixed} results from: {local_cache_file}\")\n",
    "        with open(local_cache_file, 'r') as f: fixed_beta_results = json.load(f)\n",
    "\n",
    "    if fixed_beta_results is None:\n",
    "        print(f\"\\nNo cache found. Running fixed beta={beta_fixed} simulations ({n_runs_fixed} runs each)\")\n",
    "        \n",
    "        simulation_steps_fixed = meta['max_steps']\n",
    "        DT = meta['dt']\n",
    "        DIM = meta['DIM']\n",
    "        SUCCESS_THRESHOLD = meta['success_threshold']\n",
    "        \n",
    "        B_iso = jnp.eye(DIM)\n",
    "        A_large = jnp.diag(jnp.array(meta['A_aniso_diag']))\n",
    "        B_large = jnp.sqrt(A_large)\n",
    "\n",
    "        models = {\"Isotropic\": B_iso, \"Aniso-Large\": B_large}\n",
    "        fixed_beta_results = {}\n",
    "        for name, B in models.items():\n",
    "            keys = jax.random.split(key, n_runs_fixed + 1); run_keys, key = keys[:-1], keys[-1]\n",
    "            final_Z = batch_simulate_fixed(run_keys, beta_fixed, simulation_steps_fixed, DT, B) \n",
    "            success_runs = jnp.sum(vmap(U0)(final_Z) < SUCCESS_THRESHOLD) \n",
    "            prob = float(success_runs) / n_runs_fixed\n",
    "            ci_lower, ci_upper = wilson_score_interval(prob, n_runs_fixed)\n",
    "            fixed_beta_results[name] = {\"prob\": prob, \"ci\": [ci_lower, ci_upper]}\n",
    "            print(f\"  Success Prob (Fixed Beta, {name}): {prob:.4f} (95% CI: [{ci_lower:.4f}, {ci_upper:.4f}])\")\n",
    "        \n",
    "        with open(local_cache_file, 'w') as f: json.dump(fixed_beta_results, f, indent=4)\n",
    "        print(f\"Caching new results to: {local_cache_file}\")\n",
    "\n",
    "    print(\"\\nGenerating plot for beta_target=100\")\n",
    "    sns.set_style(\"whitegrid\"); sns.set_context(\"talk\")\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    colors = {\"iso\": \"#0077b6\", \"large\": \"#f3722c\"}\n",
    "    T_max = meta['max_steps'] * meta['dt']; beta_target = meta['beta_target']\n",
    "    c_min_feasible = beta_target / math.log(T_max + 1.0)\n",
    "    ax.plot(df_iso['c'], df_iso['prob_iso'], 'o-', label=\"Annealed Isotropic\", color=colors['iso'], markersize=6, zorder=10)\n",
    "    ax.fill_between(df_iso['c'], df_iso['ci_lower'], df_iso['ci_upper'], color=colors['iso'], alpha=0.2)\n",
    "    ax.plot(df_aniso['c'], df_aniso['prob_aniso'], 's-', label=\"Annealed Aniso-Large\", color=colors['large'], markersize=6, zorder=10)\n",
    "    ax.fill_between(df_aniso['c'], df_aniso['ci_lower'], df_aniso['ci_upper'], color=colors['large'], alpha=0.2)\n",
    "    res = fixed_beta_results[\"Aniso-Large\"]\n",
    "    prob_str = f\"{res['prob']:.3f}\"; label = f'Fixed β={beta_fixed} Aniso-Large (P={prob_str})'\n",
    "    ax.axhline(y=res[\"prob\"], color=colors['large'], linestyle='--', label=label, linewidth=2.5)\n",
    "    ax.axhspan(res[\"ci\"][0], res[\"ci\"][1], color=colors['large'], alpha=0.1)\n",
    "    ax.axvline(x=c_min_feasible, color='grey', linestyle=':', linewidth=2.5, label=f'Feasibility Threshold (c≈{c_min_feasible:.2f})')\n",
    "    title_str = f\"Dynamics in the Low-Temperature Regime ($\\\\beta_{{target}}={beta_target}$)\"; ax.set_title(title_str, fontsize=20, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel(\"Annealing Rate c (log scale)\", fontsize=18, fontweight='bold'); ax.set_ylabel(\"Success Probability\", fontsize=18, fontweight='bold')\n",
    "    ax.set_xscale(\"log\"); ax.set_ylim(-0.05, 1.05)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels(): label.set_fontweight('bold')\n",
    "    ax.grid(True, which=\"both\", linestyle=':', linewidth=1.2, alpha=0.6)\n",
    "    legend = ax.legend(loc='lower right', fontsize=10, frameon=True, shadow=False, title=\"Model\", title_fontsize=13)\n",
    "    plt.setp(legend.get_title(), fontweight='bold')\n",
    "    sns.despine(); plt.tight_layout()\n",
    "    out_plot = os.path.join(save_dir, \"figure_1b.png\")\n",
    "    plt.savefig(out_plot, dpi=300); print(f\"\\n[Success] Final plot for beta_target=200 saved to {out_plot}\"); plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PATH_TO_BETA200_RESULTS = 'anisotropic_experiments/experiment1/aniso_large_beta_200/results.json'\n",
    "    PRECOMPUTED_CACHE_PATH_B200 = os.path.join(\"anisotropic_experiments\", \"experiment1\", \"fixed_beta_200_results.json\")\n",
    "    \n",
    "    final_plot_dir = \"./results/final_figures\"\n",
    "    os.makedirs(final_plot_dir, exist_ok=True)\n",
    "    \n",
    "    create_figure_1b(\n",
    "        saved_beta200_path=PATH_TO_BETA200_RESULTS,\n",
    "        save_dir=final_plot_dir,\n",
    "        precomputed_fixed_beta_path=PRECOMPUTED_CACHE_PATH_B200,\n",
    "        beta_fixed=200.0,\n",
    "        n_runs_fixed=2048\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195b3d4",
   "metadata": {},
   "source": [
    "## Experiment 2: Distribution of Hitting Times\n",
    "\n",
    "### Annealed Hitting Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_run_energy_history(key, c, n_steps, dt, B):\n",
    "    \"\"\"\n",
    "    Returns an array of length n_steps with U0(Z_t) for t=1..n_steps.\n",
    "    Accepts B, the matrix square root of the diffusion matrix A.\n",
    "    \"\"\"\n",
    "    Z0 = renormalize(jax.random.normal(key, shape=(N_POINTS, DIM)))\n",
    "\n",
    "    def step_fn(carry, t_idx):\n",
    "        Z = carry\n",
    "        t = t_idx * dt\n",
    "        beta_t = c * jnp.log(t + 1.0)\n",
    "        beta_t = jnp.maximum(beta_t, 1e-6)\n",
    "        step_key = jax.random.fold_in(key, t_idx)\n",
    "        drift = -grad_U0(Z) * dt\n",
    "        dW_ambient = jax.random.normal(step_key, shape=Z.shape)\n",
    "        dW_aniso = jnp.einsum(\"ij,bj->bi\", B, dW_ambient)\n",
    "        proj = batch_get_projection_matrix(Z)\n",
    "        dW_tangent = jnp.einsum(\"bij,bj->bi\", proj, dW_aniso)\n",
    "        noise = dW_tangent * jnp.sqrt(2 * dt / beta_t)\n",
    "\n",
    "        Z_new = renormalize(Z + drift + noise)\n",
    "        energy_new = U0(Z_new)\n",
    "        return Z_new, energy_new\n",
    "\n",
    "    _, energy_hist = jax.lax.scan(step_fn, Z0, jnp.arange(n_steps))\n",
    "    return energy_hist\n",
    "\n",
    "\n",
    "batch_simulate_energy = jit(\n",
    "    vmap(simulate_one_run_energy_history, in_axes=(0, None, None, None, None)),\n",
    "    static_argnums=(2,)\n",
    ")\n",
    "\n",
    "\n",
    "def compute_stable_hitting_times(energy_histories, threshold, max_steps, stay_duration=5):\n",
    "    \"\"\"\n",
    "    Computes the first time step where the energy drops below a threshold\n",
    "    AND stays below it for `stay_duration` consecutive steps.\n",
    "    \"\"\"\n",
    "    from scipy.signal import convolve\n",
    "\n",
    "    hits = energy_histories < threshold\n",
    "\n",
    "    # Use convolution to find consecutive hits. A run of `stay_duration` True values\n",
    "    # will result in a value of `stay_duration` in the convolution output.\n",
    "    kernel = jnp.ones(stay_duration)\n",
    "    stable_hits = convolve(hits, kernel[None, :], mode='valid') >= stay_duration\n",
    "\n",
    "    # Find the first index of a stable hit for each run\n",
    "    first_stable_hit = jnp.argmax(stable_hits, axis=1)\n",
    "    any_stable_hit = jnp.any(stable_hits, axis=1)\n",
    "\n",
    "    # If a run never had a stable hit, its time is the max number of steps\n",
    "    hitting_times = jnp.where(any_stable_hit, first_stable_hit, max_steps)\n",
    "    return np.asarray(hitting_times)\n",
    "\n",
    "def run_experiment_2_hitting_time(\n",
    "    c_values,\n",
    "    A_list,\n",
    "    beta_target=10.0,\n",
    "    dt=GLOBAL_CONFIG[\"dt\"],\n",
    "    max_steps=GLOBAL_CONFIG[\"max_steps_exp2\"],\n",
    "    n_runs=512,\n",
    "    success_threshold=GLOBAL_CONFIG[\"success_threshold\"],\n",
    "    save_dir=SAVE_DIR,\n",
    "    stay_duration=5,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    For each (c in c_values) and each A in A_list, run n_runs trajectories and compute hitting times.\n",
    "    Saves CSV per combination and summary JSON + violin plot.\n",
    "    \"\"\"\n",
    "    global key\n",
    "    results_rows = []\n",
    "\n",
    "    # create folder to store per-(c,A) files\n",
    "    out_folder = os.path.join(save_dir, \"experiment2_hitting_times\")\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    B_list = []\n",
    "    for A in A_list:\n",
    "        if A is None:  # Isotropic case\n",
    "            B_list.append(jnp.eye(DIM))\n",
    "        else:  # Anisotropic case\n",
    "            B_list.append(jnp.sqrt(A))\n",
    "\n",
    "    pbar_c = tqdm(c_values, desc=\"Exp2: c sweep\", leave=True)\n",
    "    for c in pbar_c:\n",
    "        T_final = math.exp(beta_target / float(c)) - 1.0\n",
    "        required_steps = int(min(math.ceil(T_final / dt), max_steps))\n",
    "\n",
    "        keys = jax.random.split(key, n_runs + 1)\n",
    "        run_keys, key = keys[:-1], keys[-1]\n",
    "\n",
    "        for j, B in enumerate(B_list):\n",
    "            A = A_list[j]  # Keep original A for logging/naming\n",
    "\n",
    "            energy_hists = batch_simulate_energy(run_keys, c, required_steps, dt, B)\n",
    "            energy_hists_np = np.asarray(energy_hists)\n",
    "\n",
    "            hitting_times = compute_stable_hitting_times(energy_hists_np, success_threshold, required_steps, stay_duration)\n",
    "\n",
    "            # save per-run CSV for this combination\n",
    "            a_diag = \"_\".join([f\"{float(x):.3g}\" for x in jnp.diag(A)]) if A is not None else \"isotropic\"\n",
    "            filename = os.path.join(out_folder, f\"hitting_c{c:.3g}_A{a_diag}_steps{required_steps}_runs{n_runs}.npz\")\n",
    "            np.savez_compressed(filename, energy_hists=energy_hists_np, hitting_times=hitting_times)\n",
    "\n",
    "            # append summary rows for each run \n",
    "            for run_idx, ht in enumerate(hitting_times):\n",
    "                results_rows.append({\n",
    "                    \"c\": float(c),\n",
    "                    \"A_idx\": int(j),\n",
    "                    \"A_diag\": a_diag,\n",
    "                    \"required_steps\": int(required_steps),\n",
    "                    \"run_idx\": int(run_idx),\n",
    "                    \"hitting_time_steps\": int(ht),\n",
    "                    \"beta_reached\": float(c * math.log(required_steps * dt + 1.0))\n",
    "                })\n",
    "\n",
    "            # quick summary print\n",
    "            never_frac = np.mean(hitting_times >= required_steps)\n",
    "            median_ht = np.median(hitting_times[hitting_times < required_steps]) if np.any(hitting_times < required_steps) else required_steps\n",
    "            pbar_c.set_postfix_str(f\"A={a_diag}, median_ht={median_ht:.1f}, never_hit={never_frac:.2%}\")\n",
    "\n",
    "    # Save a master csv of per-run results\n",
    "    df = pd.DataFrame(results_rows)\n",
    "    out_csv = os.path.join(save_dir, \"experiment2_hitting_times_master.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "\n",
    "    cs_sorted = np.sort(np.unique(df[\"c\"]))\n",
    "    if len(cs_sorted) >= 3:\n",
    "        rep_cs = [cs_sorted[0], cs_sorted[len(cs_sorted)//2], cs_sorted[-1]]\n",
    "    else:\n",
    "        rep_cs = list(cs_sorted)\n",
    "\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    for c_rep in rep_cs:\n",
    "        df_subset = df[df[\"c\"] == c_rep]\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.violinplot(data=df_subset, x=\"A_diag\", y=\"hitting_time_steps\", cut=0)\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(f\"Hitting Time Distribution (c={c_rep:.3g})\")\n",
    "        plt.xlabel(\"Noise model (A diag)\")\n",
    "        plt.ylabel(\"Hitting time (steps) [log scale]\")\n",
    "        plt.tight_layout()\n",
    "        out_plot = os.path.join(save_dir, f\"exp2_violin_c{c_rep:.3g}.png\")\n",
    "        plt.savefig(out_plot, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    # Also produce ECDF plot for a chosen A (e.g., hardest A, last in list)\n",
    "    chosen_A_idx = len(A_list)-1\n",
    "    df_A = df[df[\"A_idx\"] == chosen_A_idx]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for c_val in np.unique(df_A[\"c\"]):\n",
    "        subset = df_A[df_A[\"c\"] == c_val][\"hitting_time_steps\"].values\n",
    "        # compute empirical CDF\n",
    "        xs = np.sort(subset)\n",
    "        ys = np.arange(1, len(xs)+1) / len(xs)\n",
    "        plt.step(xs, ys, where='post', label=f\"c={c_val:.3g}\", alpha=0.7)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Hitting time (steps) [log scale]\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.title(f\"ECDF of hitting times for A_idx={chosen_A_idx}\")\n",
    "    plt.legend()\n",
    "    out_ecdf = os.path.join(save_dir, f\"exp2_ecdf_A{chosen_A_idx}.png\")\n",
    "    plt.savefig(out_ecdf, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    # Save summary JSON\n",
    "    summary = {\n",
    "        \"n_runs\": int(n_runs),\n",
    "        \"beta_target\": float(beta_target),\n",
    "        \"dt\": float(dt),\n",
    "        \"max_steps\": int(max_steps),\n",
    "        \"success_threshold\": float(success_threshold),\n",
    "        \"A_list_diags\": [list(map(float, jnp.diag(A))) if A is not None else \"isotropic\" for A in A_list]\n",
    "    }\n",
    "    out_summary = os.path.join(save_dir, \"experiment2_summary.json\")\n",
    "    with open(out_summary, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"[Done] Experiment 2 saved to {out_folder}, master CSV: {out_csv}, summary: {out_summary}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aadfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_A_list = [\n",
    "    None, \n",
    "    jnp.diag(jnp.array([20.0, 20.0, 10.01])),\n",
    "    jnp.diag(jnp.array([1.0, 1.0, 0.01]))\n",
    "]\n",
    "\n",
    "df_final_ht = run_experiment_2_hitting_time(\n",
    "    c_values=np.logspace(np.log10(0.1), np.log10(100), 4),\n",
    "    A_list=final_A_list,\n",
    "    beta_target=10.0,\n",
    "    n_runs=1024,\n",
    "    stay_duration=5, \n",
    "    success_threshold=-1.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c86d8",
   "metadata": {},
   "source": [
    "### Experiment 2 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c68218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def analyze_hitting_time_stats_full(csv_path):\n",
    "    \"\"\"\n",
    "    Loads hitting time data and computes a full set of summary statistics,\n",
    "    including measures of shape (skew, kurtosis).\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {csv_path}\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: File not found at {csv_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    grouped = df.groupby(['c', 'A_diag'])\n",
    "\n",
    "    summary = grouped['hitting_time_steps'].agg(\n",
    "        mean='mean',\n",
    "        median='median',\n",
    "        skew='skew',\n",
    "        kurtosis=lambda x: x.kurtosis(),\n",
    "        p25=lambda x: x.quantile(0.25),\n",
    "        p75=lambda x: x.quantile(0.75),\n",
    "        p95=lambda x: x.quantile(0.95),\n",
    "        p99=lambda x: x.quantile(0.99),\n",
    "    ).reset_index()\n",
    "\n",
    "    summary['IQR'] = summary['p75'] - summary['p25']\n",
    "\n",
    "    def failure_rate(group):\n",
    "        failed_runs = group['hitting_time_steps'] >= group['required_steps']\n",
    "        return failed_runs.mean() * 100\n",
    "\n",
    "    failures = grouped.apply(failure_rate).rename('Failure Rate (%)').reset_index()\n",
    "\n",
    "    final_summary = pd.merge(summary, failures, on=['c', 'A_diag'])\n",
    "    final_summary = final_summary[[\n",
    "        'c', 'A_diag', 'mean', 'median', 'skew', 'kurtosis',\n",
    "        'IQR', 'p95', 'p99', 'Failure Rate (%)'\n",
    "    ]]\n",
    "\n",
    "    print(\"\\n Full Summary Statistics for Hitting Times\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.width', 120):\n",
    "        print(final_summary.to_string(index=False, float_format=\"%.2f\"))\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "\n",
    "def create_figure_2(\n",
    "    csv_path,\n",
    "    save_dir,\n",
    "    c_values_to_plot=[0.1, 1.0],\n",
    "):\n",
    "    print(f\" Generating Figure 2 from: {csv_path}\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"ERROR: File not found at {csv_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    diag_labels = df['A_diag'].unique()\n",
    "    label_map = {'isotropic': 'Isotropic'}\n",
    "    # Identify the two anisotropic labels\n",
    "    aniso_labels = [l for l in diag_labels if l != 'isotropic']\n",
    "    if len(aniso_labels) == 2:\n",
    "        sum1 = sum(map(float, aniso_labels[0].split('_')))\n",
    "        sum2 = sum(map(float, aniso_labels[1].split('_')))\n",
    "        \n",
    "        if sum1 > sum2:\n",
    "            label_map[aniso_labels[0]] = 'Aniso-Large'\n",
    "            label_map[aniso_labels[1]] = 'Aniso-Small'\n",
    "        else:\n",
    "            label_map[aniso_labels[0]] = 'Aniso-Small'\n",
    "            label_map[aniso_labels[1]] = 'Aniso-Large'\n",
    "    elif len(aniso_labels) == 1:\n",
    "        print(f\"Warning: Only one anisotropic model found: {aniso_labels[0]}\")\n",
    "        # todo: better logic for determining aniso labelling\n",
    "        if '20' in aniso_labels[0]:\n",
    "             label_map[aniso_labels[0]] = 'Aniso-Large'\n",
    "        else:\n",
    "             label_map[aniso_labels[0]] = 'Aniso-Small'\n",
    "\n",
    "    print(\"Detected and mapped labels:\", label_map)\n",
    "            \n",
    "    df['Model'] = df['A_diag'].map(label_map)\n",
    "    \n",
    "    df_filtered = df[df['c'].isin(c_values_to_plot)]\n",
    "    model_order = ['Isotropic', 'Aniso-Small', 'Aniso-Large']\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"talk\")\n",
    "    fig, axes = plt.subplots(1, len(c_values_to_plot), figsize=(14, 7), sharey=True)\n",
    "    if len(c_values_to_plot) == 1: axes = [axes]\n",
    "\n",
    "    colors = {\"Isotropic\": \"#2ecc71\", \"Aniso-Small\": \"#3498db\", \"Aniso-Large\": \"#e74c3c\"}\n",
    "    \n",
    "    # Generate a Violin Plot on Each Subplot\n",
    "    for i, c_val in enumerate(c_values_to_plot):\n",
    "        ax = axes[i]\n",
    "        df_subset = df_filtered[df_filtered['c'] == c_val]\n",
    "\n",
    "        sns.violinplot(\n",
    "            data=df_subset,\n",
    "            x=\"Model\",\n",
    "            y=\"hitting_time_steps\",\n",
    "            ax=ax,\n",
    "            cut=0,\n",
    "            order=model_order,\n",
    "            palette=colors\n",
    "        )\n",
    "\n",
    "        ax.set_yscale('log')\n",
    "        if c_val < 0.5: title = f\"c = {c_val} (Slow Schedule)\"\n",
    "        elif c_val < 5: title = f\"c = {c_val} (Medium Schedule)\"\n",
    "        else: title = f\"c = {c_val} (Fast Schedule)\"\n",
    "        ax.set_title(title, fontsize=18, fontweight='bold')\n",
    "        ax.set_xlabel(\"Noise Model\", fontsize=16, fontweight='bold')\n",
    "        ax.tick_params(axis='x', labelsize=14)\n",
    "        ax.tick_params(axis='y', labelsize=14)\n",
    "        for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            label.set_fontweight('bold')\n",
    "        \n",
    "    axes[0].set_ylabel(\"Hitting Time Steps (log scale)\", fontsize=18, fontweight='bold')\n",
    "    fig.suptitle(\"Hitting Time Distribution vs. Annealing Rate\", fontsize=20, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    sns.despine(fig)\n",
    "\n",
    "    output_filename = os.path.join(save_dir, \"figure_2_hitting_times.png\")\n",
    "    plt.savefig(output_filename, dpi=300)\n",
    "    print(f\"Final Figure 2 saved to {output_filename}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    PATH_TO_CSV = 'anisotropic_experiments/experiment2/experiment2_hitting_times_master.csv'\n",
    "    FINAL_FIGURE_DIR = \"./results/final_figures\"\n",
    "    \n",
    "    create_figure_2(\n",
    "        csv_path=PATH_TO_CSV,\n",
    "        save_dir=FINAL_FIGURE_DIR,\n",
    "        c_values_to_plot=[0.1, 1.0]\n",
    "    )\n",
    "    analyze_hitting_time_stats_full(csv_path=PATH_TO_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a07ce",
   "metadata": {},
   "source": [
    "### Fixed Hitting Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf16a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_run_fixed_beta_hitting_time(key, beta_fixed, n_steps, dt, B, threshold, stay_duration):\n",
    "    Z_init = renormalize(random.normal(key, shape=(N_POINTS, DIM)))\n",
    "    NOT_FOUND = n_steps; carry_init = (Z_init, NOT_FOUND, 0)\n",
    "    def step_fn(carry, t_idx):\n",
    "        Z, hitting_time, consecutive_hits = carry\n",
    "        def update_state():\n",
    "            step_key = random.fold_in(key, t_idx); drift = -grad_U0(Z) * dt\n",
    "            dW_ambient = random.normal(step_key, shape=Z.shape); dW_aniso = jnp.einsum(\"ij,bj->bi\", B, dW_ambient)\n",
    "            proj = batch_get_projection_matrix(Z); dW_tangent = jnp.einsum(\"bij,bj->bi\", proj, dW_aniso)\n",
    "            noise = dW_tangent * jnp.sqrt(2 * dt / beta_fixed); Z_new = renormalize(Z + drift + noise)\n",
    "            energy_new = U0(Z_new); is_below = energy_new < threshold\n",
    "            new_consecutive = lax.select(is_below, consecutive_hits + 1, 0)\n",
    "            just_hit_stably = (new_consecutive == stay_duration); time_of_hit = t_idx - stay_duration + 1\n",
    "            new_hitting_time = lax.select(just_hit_stably, time_of_hit, NOT_FOUND)\n",
    "            return (Z_new, new_hitting_time, new_consecutive)\n",
    "        def pass_through_state(): return carry\n",
    "        return lax.cond(hitting_time == NOT_FOUND, update_state, pass_through_state), None\n",
    "    final_carry, _ = lax.scan(step_fn, carry_init, jnp.arange(n_steps))\n",
    "    return final_carry[1]\n",
    "\n",
    "batch_simulate_fixed_hitting_time = jit(\n",
    "    vmap(simulate_one_run_fixed_beta_hitting_time, in_axes=(0, None, None, None, None, None, None)),\n",
    "    static_argnums=(2, 5, 6)\n",
    ")\n",
    "\n",
    "\n",
    "def get_fixed_beta_hitting_time_stats(\n",
    "    beta_fixed=10.0,\n",
    "    n_runs=2048,\n",
    "    simulation_steps=200000,\n",
    "    stay_duration=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs simulations for fixed beta and prints a full summary statistics table.\n",
    "    \"\"\"\n",
    "    global key\n",
    "    A_small = jnp.diag(jnp.array([1.0, 1.0, 0.1]))\n",
    "    A_large = jnp.diag(jnp.array([20.0, 20.0, 10.0]))\n",
    "    models = {\n",
    "        \"Isotropic\": jnp.eye(DIM),\n",
    "        \"Aniso-Small\": jnp.sqrt(A_small),\n",
    "        \"Aniso-Large\": jnp.sqrt(A_large)\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    print(f\" Running Fixed Beta={beta_fixed} Hitting Time Simulations\")\n",
    "    \n",
    "    for name, B in tqdm(models.items(), desc=\"Simulating Models\"):\n",
    "        run_keys = random.split(key, n_runs)\n",
    "        key = random.fold_in(key, n_runs)\n",
    "        \n",
    "        hitting_times = batch_simulate_fixed_hitting_time(\n",
    "            run_keys, beta_fixed, simulation_steps, DT, B, SUCCESS_THRESHOLD, stay_duration\n",
    "        )\n",
    "        # Store all individual hitting times for later analysis\n",
    "        for ht in np.asarray(hitting_times):\n",
    "            all_results.append({\"Model\": name, \"hitting_time\": int(ht)})\n",
    "\n",
    "    df_full = pd.DataFrame(all_results)\n",
    "    \n",
    "    grouped = df_full.groupby('Model')\n",
    "    \n",
    "    summary = grouped['hitting_time'].agg(\n",
    "        mean='mean',\n",
    "        median='median',\n",
    "        skew='skew',\n",
    "        kurtosis=lambda x: x.kurtosis(),\n",
    "        p25=lambda x: x.quantile(0.25),\n",
    "        p75=lambda x: x.quantile(0.75),\n",
    "        p95=lambda x: x.quantile(0.95),\n",
    "        p99=lambda x: x.quantile(0.99),\n",
    "    ).reset_index()\n",
    "\n",
    "    summary['IQR'] = summary['p75'] - summary['p25']\n",
    "\n",
    "    def failure_rate(group):\n",
    "        # All runs in a group have the same max_steps\n",
    "        failed_runs = group['hitting_time'] >= simulation_steps\n",
    "        return failed_runs.mean() * 100\n",
    "\n",
    "    failures = grouped.apply(failure_rate).rename('Failure Rate (%)').reset_index()\n",
    "    \n",
    "    final_summary = pd.merge(summary, failures, on='Model')\n",
    "\n",
    "    final_summary = final_summary[[\n",
    "        'Model', 'mean', 'median', 'skew', 'kurtosis', 'IQR', 'p95', 'p99', 'Failure Rate (%)'\n",
    "    ]]\n",
    "    \n",
    "    # Ensure the models are in a consistent order for printing\n",
    "    model_order = [\"Isotropic\", \"Aniso-Small\", \"Aniso-Large\"]\n",
    "    final_summary['Model'] = pd.Categorical(final_summary['Model'], categories=model_order, ordered=True)\n",
    "    final_summary = final_summary.sort_values('Model')\n",
    "\n",
    "    print(f\"\\n Full Summary Statistics for Fixed Beta={beta_fixed} Hitting Times\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.width', 120):\n",
    "        print(final_summary.to_string(index=False, float_format=\"%.2f\"))\n",
    "        \n",
    "    return final_summary\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\" Calculating stats for beta=10.0\")\n",
    "    fixed_beta_10_summary = get_fixed_beta_hitting_time_stats(beta_fixed=10.0)\n",
    "    \n",
    "    print(\"\\n\\n Calculating stats for beta=100.0\")\n",
    "    fixed_beta_100_summary = get_fixed_beta_hitting_time_stats(beta_fixed=100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
